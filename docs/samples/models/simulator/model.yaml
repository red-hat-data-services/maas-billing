apiVersion: serving.kserve.io/v1alpha1
kind: LLMInferenceService
metadata:
  name: simulated
  annotations:
    alpha.maas.opendatahub.io/tiers: '[]'
spec:
  model:
    uri: hf://facebook/opt-125m
    name: facebook/opt-125m
  replicas: 1
  router: 
    route: {}
    # Connect to MaaS-enabled gateway
    gateway:
      refs:
        - name: maas-default-gateway
          namespace: openshift-ingress
  template:
    containers:
      - name: main
        image: "ghcr.io/llm-d/llm-d-inference-sim:v0.5.1"
        imagePullPolicy: Always
        command: ["/app/llm-d-inference-sim"]
        args:
        - --port
        - "8000" 
        - --model
        - facebook/opt-125m
        - --mode
        - random
        - --ssl-certfile
        - /etc/ssl/certs/tls.crt
        - --ssl-keyfile
        - /etc/ssl/certs/tls.key
        env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
        ports:
          - name: https
            containerPort: 8000
            protocol: TCP
        livenessProbe:
          httpGet:
            path: /health
            port: https
            scheme: HTTPS
        readinessProbe:
          httpGet:
            path: /ready
            port: https
            scheme: HTTPS
